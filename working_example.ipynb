{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoassigner\n",
    "import numpy as np\n",
    "from gurobipy import GRB, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper: Optimal Assignment\n",
    "\n",
    "First, we provide a naive implementation of the HARD algorithm to compute an optimally fair assignment in exponential time. In several examples below, we will compare the fairness of the PR4A algorithm with the optimal fairness achieved by HARD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_assignment(similarity, demand, ability, function = lambda x: x):\n",
    "    \n",
    "    problem = Model()\n",
    "    numrev = similarity.shape[0]\n",
    "    numpap = similarity.shape[1]\n",
    "    \n",
    "    \n",
    "    #Optimization variables\n",
    "    frac_assignment = problem.addVars(numrev, numpap, lb=0.0, ub=1.0, vtype=GRB.BINARY) \n",
    "    \n",
    "    \n",
    "    #Paper- and Reviewer-load constraints\n",
    "    paperload = problem.addConstrs(frac_assignment.sum('*', paper) == demand for paper in range(numpap))\n",
    "    revload = problem.addConstrs(frac_assignment.sum(reviewer, '*') <= ability for reviewer in range(numrev))\n",
    "\n",
    "    #Optimilzation\n",
    "    \n",
    "    #Step1. Create an auxiliary variable\n",
    "    threshold = problem.addVar(vtype=GRB.CONTINUOUS)\n",
    "    \n",
    "    #Step2. Request that each paper is assigned reviewers with total similarity higher than threshold\n",
    "    maximization = problem.addConstrs(sum([frac_assignment[(reviewer, paper)]*function(similarity[reviewer, paper]) \n",
    "                                             for reviewer in range(numrev)]) >= threshold \n",
    "                                             for paper in range(numpap)) \n",
    "    \n",
    "    #Step3. Maximize threshold threshold\n",
    "    problem.setObjective(threshold, GRB.MAXIMIZE)\n",
    "\n",
    "    problem.setParam('OutputFlag', False)\n",
    "    problem.optimize()\n",
    "    \n",
    "    #Construct the assignment\n",
    "\n",
    "    hard_assignment_paper = {}\n",
    "    for paper in range(numpap):\n",
    "        hard_assignment_paper[paper] = [reviewer for reviewer in range(numrev) if \n",
    "                                          int(frac_assignment[(reviewer, paper)].X) == 1]\n",
    "    \n",
    "    #Output fairness of the assignment and the assignment itself\n",
    "    return problem.objVal, hard_assignment_paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we construct a similarity matrix for which the TPMS algorithm outputs an unfair assignment. Indeed, it is not hard to see that in this case TPMS assigns one of the papers to a reviewer who has 0 similarity with this paper. In contrast, PR4A and HARD algorithms assign each paper to a reviewer with a non-zero similarity, both leading the an optimally fair assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.   1.   1.  ]\n",
      " [0.   0.   0.24]\n",
      " [0.25 0.25 0.5 ]]\n"
     ]
    }
   ],
   "source": [
    "similarity0 = np.matrix([[1., 1., 1.], \n",
    "                         [0., 0., 1./4-0.01], \n",
    "                         [1./4, 1./4, 1./2]])\n",
    "\n",
    "print(similarity0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2021-07-02\n",
      "Using license file /Users/stiv/gurobi.lic\n",
      "Fairness of the PR4A assignment: 0.24\n",
      "Fairness of the HARD assignment: 0.24\n",
      "PR4A assignment: {0: [0], 1: [2], 2: [1]}\n"
     ]
    }
   ],
   "source": [
    "a = autoassigner.auto_assigner(similarity0, 1, 1)\n",
    "a.fair_assignment()\n",
    "\n",
    "b = hard_assignment(similarity0, 1, 1)\n",
    "\n",
    "print('Fairness of the PR4A assignment:', \"%.2f\" % a.best_quality)\n",
    "print('Fairness of the HARD assignment:', \"%.2f\" % b[0])\n",
    "\n",
    "\n",
    "print('PR4A assignment:', a.fa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates how the number of iterations of Steps 2 -- 7 of the PR4A algorithm impacts the assignment. Specifically, we use PR4A to compute two assignments: the first assignment uses only 1 iteration of Steps 2 -- 7 and the second assignment uses 2 iterations.\n",
    "\n",
    "First, observe that fairness of both assignments is the same (it is always the case -- the first iteration already satisfies fairness guarantees of Theorem 1 in the paper).\n",
    "\n",
    "Second, observe that two assignments differ in what reviewer is assigned to the second worst-off paper. One-iteration assignment assigns paper 1 to reviewer 0 (similarity 0.04) and paper 2 to reviewer 2 (similarity 1). In contrast, two-iteration assignment assigns paper 1 to reviewer 2 (similarity 0.1) and paper 2 to reviewer 0 (similarity 0.1). Thus, the second iteration helps to promote fairness beyond the most worst-off paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.04 0.1 ]\n",
      " [0.01 0.05 0.  ]\n",
      " [0.   0.1  1.  ]]\n"
     ]
    }
   ],
   "source": [
    "similarity1 = np.matrix([[0, 4./100, 10./100],[1./100, 5./100, 0],[0, 10./100, 100./100]])\n",
    "\n",
    "print(similarity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fairness of the PR4A assignment (1 iteration):  0.01\n",
      "Fairness of the PR4A assignment (2 iterations): 0.01\n",
      "Fairness of the HARD assignment: 0.01\n",
      "PR4A (1 iteration) assignment:  {0: [1], 1: [0], 2: [2]}\n",
      "PR4A (2 iterations) assignment: {0: [1], 1: [2], 2: [0]}\n"
     ]
    }
   ],
   "source": [
    "a1_1 = autoassigner.auto_assigner(similarity1, 1, 1, iter_limit=1, time_limit=1)\n",
    "a1_2 = autoassigner.auto_assigner(similarity1, 1, 1, iter_limit=2, time_limit=1)\n",
    "\n",
    "a1_1.fair_assignment()\n",
    "a1_2.fair_assignment()\n",
    "\n",
    "b1 = hard_assignment(similarity1, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "print('Fairness of the PR4A assignment (1 iteration): ', \"%.2f\" % a1_1.best_quality)\n",
    "print('Fairness of the PR4A assignment (2 iterations):', \"%.2f\" % a1_1.best_quality)\n",
    "\n",
    "\n",
    "print('Fairness of the HARD assignment:', \"%.2f\" % b1[0])\n",
    "\n",
    "print('PR4A (1 iteration) assignment: ', a1_1.fa)\n",
    "print('PR4A (2 iterations) assignment:', a1_2.fa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the last example operates with the similarity matrix from Case C4 of synthetic simulations (Section 8.1 of the paper) for 100 papers and 100 reviewers. Note that in this case we use the MLE transformation function. See the paper for details and discsussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 4\n",
    "k = 2\n",
    "EPS = 1e-3\n",
    "\n",
    "numrev = 100\n",
    "numpap = 100\n",
    "\n",
    "tmp_similarity2 = np.zeros((k * lam**2, k * lam**2))\n",
    "\n",
    "tmp = 1./100\n",
    "\n",
    "tmp_similarity2[0, :k] = 1./lam + EPS\n",
    "tmp_similarity2[0, k:k*lam] = 1./lam\n",
    "\n",
    "for itr in range(k):\n",
    "    tmp_similarity2[itr + 1, itr] = 1\n",
    "    tmp_similarity2[itr + 1, (k * lam):] = tmp\n",
    "    \n",
    "tmp_similarity2[(k+1):, : (k*lam)] = 1.\n",
    "tmp_similarity2[-k*(lam-1):, (k*lam):] = 1./lam\n",
    "\n",
    "cur_papers = k*lam**2 - k*lam\n",
    "cur_row = k*lam**2 - k*lam\n",
    "cur_col = k*lam\n",
    "\n",
    "for iteration in range(2, lam + 1):\n",
    "    if cur_col > k*lam:\n",
    "        tmp_similarity2[cur_row, cur_col:] = tmp\n",
    "        cur_row -= 1\n",
    "        cur_papers -= 1\n",
    "        cur_col = k*lam\n",
    "    demand = cur_papers * iteration\n",
    "    ability = k*lam ** 2\n",
    "    while (demand - ability) // (lam) > 0:\n",
    "        tmp_similarity2[cur_row, cur_col:] = tmp\n",
    "        cur_row -= 1\n",
    "        demand = demand - iteration \n",
    "        cur_col = k*lam\n",
    "        cur_papers -= 1\n",
    "    while demand > ability:\n",
    "        tmp_similarity2[cur_row, cur_col] = tmp\n",
    "        cur_col += 1\n",
    "        demand -= 1\n",
    "    tmp = tmp / 2  \n",
    "\n",
    "tmp_similarity2 = 10 * tmp_similarity2\n",
    "tmp_similarity2 = tmp_similarity2 + 1\n",
    "tmp_similarity2 = tmp_similarity2.T\n",
    "\n",
    "similarity2 = np.ones((numrev, numpap))\n",
    "similarity2[0:k * lam**2, 0:k * lam**2] = tmp_similarity2\n",
    "similarity2[k * lam**2:, k * lam**2:] = 10*np.ones((numrev - k * lam**2, numpap - k * lam**2))\n",
    "\n",
    "similarity2 = 1 - 1./similarity2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fairness of the PR4A assignment: 6.51\n",
      "Fairness of the HARD assignment: 14.00\n"
     ]
    }
   ],
   "source": [
    "mle_transformation = lambda x: 1 / (1 - x) \n",
    "\n",
    "a2 = autoassigner.auto_assigner(similarity2, 4, 4, function=mle_transformation, iter_limit=1, time_limit=1)\n",
    "a2.fair_assignment()\n",
    "\n",
    "b2 = hard_assignment(similarity2, 4, 4, function=mle_transformation)\n",
    "\n",
    "print('Fairness of the PR4A assignment:', \"%.2f\" % a2.best_quality)\n",
    "print('Fairness of the HARD assignment:', \"%.2f\" % b2[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
